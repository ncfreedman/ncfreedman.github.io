<!DOCTYPE html>
<html>
<title>Noah Chaim Freedman</title>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
    }
    });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<meta charset="UTF-8">
<script src="jquery.js"></script>
<script>$(function(){$("#header").load("header.html");});</script>
<script>$(function(){$("#footer").load("footer.html");});</script>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="icon" href="cube.png">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
body,h1,h2,h3,h4,h5,h6 {font-family: "Raleway", sans-serif}

.sidebar {
  margin: 0;
  padding: 0;
  width: 300px;
  background-color: #f1f1f1;
  position: fixed;
  height: 100%;
  overflow: auto;
}

@media screen and (max-width: 1000px) {
  .sidebar {
    width: 100%;
    height: auto;
    position: relative;
  }
  div.content {margin-left: 0;}
}

@media screen and (max-width: 400px) {
  .sidebar a {
    text-align: center;
    float: none;
  }
}

</style>
<body class="w3-white w3-content" style="max-width:1600px">

<div id="header"></div>

<div class="w3-main" style="margin-left:15%;margin-right:15%;text-align:justify">
    <br>
    <header>
        <div class="w3-container">
            <h1><b><font size="+7">Kalman Filter</font></b></h1>
        </div>
    </header>
    <div class="w3-container w3-padding-large" style="margin-bottom:32px"><font size="+2">
Kalman filters are nifty modelling and decoding methods for linear dynamical systems having some hidden or latent variables along with observables which are linearly related to the variables. This discussion will pertain to systems with mean \(0\) latent variables \(z\) and observables \(x\). Specifically, let's say we have the following state evolution model<br><br>

\[z_1\sim N(\pi, V)\]
\[z_t|z_{t-1}\sim N(Az_{t-1}, Q)\]<br>

along with an observation model<br><br>

\[x_t|z_t\sim N(Cz_t, R)\]<br>

Given a set of observations \(\{x_t\}_{t=1}^{N}\), or more generally a set of a set of observations (I won't discuss this here for notational simplicity), we can estimate our model parameters using the EM algorithm. On the other hand, if we have access to the latent variables, we can proceed by simply writing the log likelihood and solving for our parameters by setting partial derivatives to zero.<br><br>

Given fitted parameters, we can now estimate latent variables from observations by maximizing \(P(z_t|\{x_s\}_{s=1}^t)\) w.r.t. \(z_t\). This turns out be Gaussian so finding the mean is sufficient and can be achieved by iterating the following steps:
    </font></div>
</div>

<div id="footer"></div>
</body>
</html>
